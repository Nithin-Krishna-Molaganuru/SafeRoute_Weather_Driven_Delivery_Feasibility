{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715d7232",
   "metadata": {},
   "source": [
    "# SafeRoute: Weather-Driven Delivery Feasibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afcf798",
   "metadata": {},
   "source": [
    "### Understanding Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877ffee",
   "metadata": {},
   "source": [
    "#### This is an Weather Data and the task is to Predict whether a given hourly weather record makes same-day local ground delivery risky/delayed so logistics can re-route, delay or add buffers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83535c71",
   "metadata": {},
   "source": [
    "##### For delivery to happen there are few favourable conditions need to be met to make deliveries happen, they are \n",
    "##### 1. Temperature > 0\n",
    "##### 2. Wind Speed <= 40\n",
    "##### 3. Visibility > 2\n",
    "##### 4. No Weather conditions like Rain, Rain Showers, Fog, Thunderstorms, Snow Showers, Snow Pellets, Freezing Rain, Snow, Blowing Snow, Ice Pellets, Heavy Rain Showers etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7e49e",
   "metadata": {},
   "source": [
    "### Loading DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c146a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8784 entries, 0 to 8783\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Date/Time         8784 non-null   object \n",
      " 1   Temp_C            8784 non-null   float64\n",
      " 2   Dew Point Temp_C  8784 non-null   float64\n",
      " 3   Rel Hum_%         8784 non-null   int64  \n",
      " 4   Wind Speed_km/h   8784 non-null   int64  \n",
      " 5   Visibility_km     8784 non-null   float64\n",
      " 6   Press_kPa         8784 non-null   float64\n",
      " 7   Weather           8784 non-null   object \n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 549.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Weather.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980f4fd",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ce6a6",
   "metadata": {},
   "source": [
    "##### Form the info tab we can see there are :-\n",
    "##### 1. NO Null values in the dataset\n",
    "##### 2. Date/Time column is an Object so lets clean timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304c73f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1/1/2012 0:00\n",
       "1    1/1/2012 1:00\n",
       "2    1/1/2012 2:00\n",
       "3    1/1/2012 3:00\n",
       "4    1/1/2012 4:00\n",
       "Name: Date/Time, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before Conversion of Date/Time\n",
    "df[\"Date/Time\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800f847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2012-01-01 00:00:00\n",
       "1   2012-01-01 01:00:00\n",
       "2   2012-01-01 02:00:00\n",
       "3   2012-01-01 03:00:00\n",
       "4   2012-01-01 04:00:00\n",
       "Name: Date/Time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After Conversion to DateTime\n",
    "df[\"Date/Time\"] = pd.to_datetime(df[\"Date/Time\"])\n",
    "df[\"Date/Time\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05533f",
   "metadata": {},
   "source": [
    "#### Label Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4a8a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delivery_Risk\n",
       "Safe       0.633766\n",
       "Risky      0.253643\n",
       "Caution    0.112591\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new label for the Weather Column to understand whether delivery can be possible\n",
    "def delivery_risk(df):\n",
    "    risky = ['Rain', 'Rain Showers', 'Fog', 'Thunderstorms', 'Snow Showers', 'Snow Pellets','Freezing Rain', 'Snow', 'Blowing Snow', 'Ice Pellets', 'Heavy Rain Showers']\n",
    "    \n",
    "    def classify(row):\n",
    "        temp_ok = row[\"Temp_C\"] > 0\n",
    "        visibility_ok = row[\"Visibility_km\"] > 2\n",
    "        wind_ok = row[\"Wind Speed_km/h\"] <= 40\n",
    "        weather_ok = not any(risk in str(row[\"Weather\"]) for risk in risky)\n",
    "\n",
    "        if temp_ok and visibility_ok and wind_ok and weather_ok:\n",
    "            return 'Safe'\n",
    "        elif temp_ok and visibility_ok and weather_ok and not wind_ok:\n",
    "            return 'Caution'  # Wind is high, others are okay\n",
    "        elif temp_ok and visibility_ok:\n",
    "            return 'Caution'  # Weather or wind may be risky\n",
    "        else:\n",
    "            return 'Risky'\n",
    "\n",
    "    df[\"Delivery_Risk\"] = df.apply(classify, axis = 1)\n",
    "    return df[\"Delivery_Risk\"].value_counts(normalize = True)\n",
    "delivery_risk(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7f8981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delivery_Risk\n",
       "Safe       5567\n",
       "Risky      2228\n",
       "Caution     989\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Delivery_Risk\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a11a996",
   "metadata": {},
   "source": [
    "#### Encoding for Delivery_Risk Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3be016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labelled_Delivery_Risk\n",
       "2    5567\n",
       "1    2228\n",
       "0     989\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"Labelled_Delivery_Risk\"] = le.fit_transform(df[\"Delivery_Risk\"])\n",
    "df[\"Labelled_Delivery_Risk\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2be266",
   "metadata": {},
   "source": [
    "#### Auto EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf268abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\DA\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 206.12it/s]00:00, 36.48it/s, Describe variable: Labelled_Delivery_Risk]\n",
      "Summarize dataset: 100%|██████████| 55/55 [00:04<00:00, 13.44it/s, Completed]                                 \n",
      "Generate report structure: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 63.32it/s]\n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "report = ProfileReport(\n",
    "    df,\n",
    "    title = \"EDA_Report\",\n",
    "    explorative= True,\n",
    ")\n",
    "report.to_file(\"Y_EDA_Report.html\")\n",
    "ai_report = report.to_json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285970f",
   "metadata": {},
   "source": [
    "##### Adding rolling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f289629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_feature(df, col_name):\n",
    "    df[f\"{col_name}_rolling_mean\"] = df[col_name].rolling(window = 3).mean()\n",
    "    df[f\"{col_name}_rolling_mean\"] = df[f\"{col_name}_rolling_mean\"].fillna(df[col_name].expanding().mean())\n",
    "\n",
    "    df[f\"{col_name}_rolling_std\"] = df[col_name].rolling(window = 3).std()\n",
    "    df[f\"{col_name}_rolling_std\"] = df[f\"{col_name}_rolling_std\"].fillna(df[col_name].expanding().std().fillna(0))\n",
    "\n",
    "\n",
    "rolling_feature(df,\"Temp_C\")\n",
    "rolling_feature(df, \"Dew Point Temp_C\")\n",
    "rolling_feature(df, \"Rel Hum_%\")\n",
    "rolling_feature(df, \"Wind Speed_km/h\")\n",
    "rolling_feature(df, \"Visibility_km\")\n",
    "rolling_feature(df, \"Press_kPa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578e2c1a",
   "metadata": {},
   "source": [
    "##### Train and Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0369556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train and test dat at 80/20 ratio with target stratification\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df[\"Labelled_Delivery_Risk\"],random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0656d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 354.26it/s]<00:00, 47.30it/s, Describe variable: Press_kPa_rolling_std]      \n",
      "Summarize dataset: 100%|██████████| 355/355 [00:29<00:00, 12.07it/s, Completed]                                                           \n",
      "Generate report structure: 100%|██████████| 1/1 [00:04<00:00,  4.88s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:06<00:00,  6.33s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# individual EDA for Train and Test\n",
    "# For Train\n",
    "train_report = ProfileReport(df = train, title=\"Y_Train_EDA_Report\", explorative=True)\n",
    "train_report.to_file(\"Y_Train_EDA.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aba4e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<?, ?it/s]27 [00:00<00:00, 52.46it/s, Describe variable: Press_kPa_rolling_std]      \n",
      "Summarize dataset: 100%|██████████| 355/355 [00:29<00:00, 12.01it/s, Completed]                                                           \n",
      "Generate report structure: 100%|██████████| 1/1 [00:04<00:00,  4.76s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:06<00:00,  6.28s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 17.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# For Test\n",
    "test_report = ProfileReport(df = test, title=\"Y_Test_EDA_Report\", explorative=True)\n",
    "test_report.to_file(\"Y_Test_EDA.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "572f36c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate report structure: 100%|██████████| 1/1 [00:07<00:00,  7.60s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:11<00:00, 11.98s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compare Test and Train data\n",
    "compare_report = train_report.compare(test_report)\n",
    "compare_report.to_file(\"Y_Compare_Train_Test.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848965cc",
   "metadata": {},
   "source": [
    "#### Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f104dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(columns=[\"Labelled_Delivery_Risk\", \"Date/Time\",\"Weather\",\"Delivery_Risk\"])\n",
    "y = df[\"Labelled_Delivery_Risk\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc42edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 10-09 14:38:45] {1752} INFO - task = classification\n",
      "[flaml.automl.logger: 10-09 14:38:45] {1763} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 10-09 14:38:45] {1862} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 10-09 14:38:45] {1979} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'lrl1']\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2417} INFO - Estimated sufficient time budget=239s. Estimated necessary time budget=6s.\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.1s,\testimator lgbm's best error=0.1133,\tbest estimator lgbm's best error=0.1133\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.1s,\testimator lgbm's best error=0.1133,\tbest estimator lgbm's best error=0.1133\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 2, current learner sgd\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.3s,\testimator sgd's best error=0.3640,\tbest estimator lgbm's best error=0.1133\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.4s,\testimator lgbm's best error=0.0680,\tbest estimator lgbm's best error=0.0680\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.4s,\testimator xgboost's best error=0.0637,\tbest estimator xgboost's best error=0.0637\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.4s,\testimator lgbm's best error=0.0581,\tbest estimator lgbm's best error=0.0581\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.4s,\testimator lgbm's best error=0.0581,\tbest estimator lgbm's best error=0.0581\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.5s,\testimator lgbm's best error=0.0581,\tbest estimator lgbm's best error=0.0581\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.5s,\testimator lgbm's best error=0.0581,\tbest estimator lgbm's best error=0.0581\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.5s,\testimator lgbm's best error=0.0552,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.6s,\testimator xgboost's best error=0.0637,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.6s,\testimator xgboost's best error=0.0623,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.7s,\testimator extra_tree's best error=0.2153,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2466} INFO -  at 0.8s,\testimator rf's best error=0.0949,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:45] {2282} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 0.9s,\testimator rf's best error=0.0949,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.0s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.1s,\testimator extra_tree's best error=0.2153,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.1s,\testimator lgbm's best error=0.0552,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 18, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.2s,\testimator extra_tree's best error=0.1176,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.2s,\testimator lgbm's best error=0.0552,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.3s,\testimator xgboost's best error=0.0623,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.4s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 22, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.5s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.5s,\testimator lgbm's best error=0.0552,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.6s,\testimator lgbm's best error=0.0552,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.7s,\testimator extra_tree's best error=0.1176,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 26, current learner sgd\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2466} INFO -  at 1.8s,\testimator sgd's best error=0.3640,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:46] {2282} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 1.9s,\testimator lgbm's best error=0.0552,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 1.9s,\testimator xgboost's best error=0.0567,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 2.0s,\testimator extra_tree's best error=0.1176,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 2.1s,\testimator extra_tree's best error=0.1176,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 2.1s,\testimator lgbm's best error=0.0552,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 2.2s,\testimator lgbm's best error=0.0552,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 2.3s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 2.3s,\testimator xgboost's best error=0.0567,\tbest estimator lgbm's best error=0.0552\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 2.4s,\testimator lgbm's best error=0.0524,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2466} INFO -  at 2.5s,\testimator xgboost's best error=0.0567,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:47] {2282} INFO - iteration 37, current learner sgd\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2466} INFO -  at 2.8s,\testimator sgd's best error=0.1388,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2282} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2466} INFO -  at 2.9s,\testimator xgboost's best error=0.0567,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2282} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2466} INFO -  at 2.9s,\testimator xgboost's best error=0.0567,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2282} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2466} INFO -  at 3.0s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2282} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2466} INFO -  at 3.1s,\testimator xgboost's best error=0.0538,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2282} INFO - iteration 42, current learner sgd\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2466} INFO -  at 3.4s,\testimator sgd's best error=0.1388,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2282} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2466} INFO -  at 3.5s,\testimator lgbm's best error=0.0524,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2282} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2466} INFO -  at 3.5s,\testimator xgboost's best error=0.0538,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:48] {2282} INFO - iteration 45, current learner sgd\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2466} INFO -  at 3.9s,\testimator sgd's best error=0.1176,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2282} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2466} INFO -  at 3.9s,\testimator xgboost's best error=0.0538,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2282} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2466} INFO -  at 3.9s,\testimator lgbm's best error=0.0524,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2282} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2466} INFO -  at 4.0s,\testimator xgboost's best error=0.0538,\tbest estimator lgbm's best error=0.0524\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2282} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2466} INFO -  at 4.3s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:49] {2282} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:50] {2466} INFO -  at 5.0s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:50] {2282} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:50] {2466} INFO -  at 5.1s,\testimator extra_tree's best error=0.1176,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:50] {2282} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:50] {2466} INFO -  at 5.2s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:50] {2282} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:50] {2466} INFO -  at 5.4s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:50] {2282} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2466} INFO -  at 6.0s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2282} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2466} INFO -  at 6.1s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2282} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2466} INFO -  at 6.2s,\testimator extra_tree's best error=0.1176,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2282} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2466} INFO -  at 6.3s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2282} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2466} INFO -  at 6.4s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2282} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2466} INFO -  at 6.6s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:51] {2282} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2466} INFO -  at 6.9s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2282} INFO - iteration 61, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2466} INFO -  at 7.1s,\testimator extra_tree's best error=0.1176,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2282} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2466} INFO -  at 7.5s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2282} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2466} INFO -  at 7.5s,\testimator xgboost's best error=0.0538,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2282} INFO - iteration 64, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2466} INFO -  at 7.7s,\testimator extra_tree's best error=0.1176,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:52] {2282} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2466} INFO -  at 8.1s,\testimator lgbm's best error=0.0425,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2282} INFO - iteration 66, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2466} INFO -  at 8.2s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2282} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2466} INFO -  at 8.3s,\testimator extra_tree's best error=0.1048,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2282} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2466} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.0581,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2282} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2466} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.0581,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2282} INFO - iteration 70, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2466} INFO -  at 8.5s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2282} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2466} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.0538,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2282} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2466} INFO -  at 8.7s,\testimator xgb_limitdepth's best error=0.0538,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:53] {2282} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:54] {2466} INFO -  at 8.9s,\testimator extra_tree's best error=0.0807,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:54] {2282} INFO - iteration 74, current learner sgd\n",
      "[flaml.automl.logger: 10-09 14:38:55] {2466} INFO -  at 10.5s,\testimator sgd's best error=0.1176,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:55] {2282} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:55] {2466} INFO -  at 10.6s,\testimator extra_tree's best error=0.0807,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:55] {2282} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:55] {2466} INFO -  at 10.7s,\testimator xgb_limitdepth's best error=0.0482,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:55] {2282} INFO - iteration 77, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:55] {2466} INFO -  at 10.8s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:55] {2282} INFO - iteration 78, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2466} INFO -  at 10.9s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2282} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2466} INFO -  at 10.9s,\testimator xgb_limitdepth's best error=0.0482,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2282} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2466} INFO -  at 11.1s,\testimator extra_tree's best error=0.0765,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2282} INFO - iteration 81, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2466} INFO -  at 11.2s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2282} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2466} INFO -  at 11.4s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2282} INFO - iteration 83, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2466} INFO -  at 11.6s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2282} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2466} INFO -  at 11.7s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2282} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2466} INFO -  at 11.8s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:56] {2282} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2466} INFO -  at 12.0s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2282} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2466} INFO -  at 12.1s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2282} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2466} INFO -  at 12.4s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2282} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2466} INFO -  at 12.4s,\testimator xgboost's best error=0.0524,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2282} INFO - iteration 90, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2466} INFO -  at 12.6s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2282} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2466} INFO -  at 12.7s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2282} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2466} INFO -  at 12.7s,\testimator xgboost's best error=0.0524,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:57] {2282} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2466} INFO -  at 13.1s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2282} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2466} INFO -  at 13.2s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2282} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2466} INFO -  at 13.3s,\testimator extra_tree's best error=0.0765,\tbest estimator lgbm's best error=0.0425\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2282} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2466} INFO -  at 13.7s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2282} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2466} INFO -  at 13.8s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:38:58] {2282} INFO - iteration 98, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:38:59] {2466} INFO -  at 13.9s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:38:59] {2282} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:59] {2466} INFO -  at 14.2s,\testimator xgboost's best error=0.0482,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:38:59] {2282} INFO - iteration 100, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:38:59] {2466} INFO -  at 14.8s,\testimator xgboost's best error=0.0482,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:38:59] {2282} INFO - iteration 101, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:39:00] {2466} INFO -  at 14.9s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:00] {2282} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:39:00] {2466} INFO -  at 15.3s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:00] {2282} INFO - iteration 103, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:01] {2466} INFO -  at 15.9s,\testimator xgboost's best error=0.0482,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:01] {2282} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:01] {2466} INFO -  at 16.2s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:01] {2282} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2466} INFO -  at 16.8s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2282} INFO - iteration 106, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2466} INFO -  at 17.0s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2282} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2466} INFO -  at 17.3s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2282} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2466} INFO -  at 17.4s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2282} INFO - iteration 109, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2466} INFO -  at 17.5s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2282} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2466} INFO -  at 17.6s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:02] {2282} INFO - iteration 111, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:04] {2466} INFO -  at 19.5s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:04] {2282} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:05] {2466} INFO -  at 19.9s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:05] {2282} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:39:05] {2466} INFO -  at 20.0s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:05] {2282} INFO - iteration 114, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:05] {2466} INFO -  at 20.5s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:05] {2282} INFO - iteration 115, current learner sgd\n",
      "[flaml.automl.logger: 10-09 14:39:05] {2466} INFO -  at 20.6s,\testimator sgd's best error=0.1091,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:05] {2282} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:06] {2466} INFO -  at 21.0s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:06] {2282} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:06] {2466} INFO -  at 21.2s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:06] {2282} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:39:06] {2466} INFO -  at 21.3s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:06] {2282} INFO - iteration 119, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:07] {2466} INFO -  at 22.2s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:07] {2282} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:07] {2466} INFO -  at 22.5s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:07] {2282} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:07] {2466} INFO -  at 22.6s,\testimator extra_tree's best error=0.0765,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:07] {2282} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:07] {2466} INFO -  at 22.8s,\testimator extra_tree's best error=0.0652,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:07] {2282} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2466} INFO -  at 23.1s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2282} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2466} INFO -  at 23.2s,\testimator extra_tree's best error=0.0652,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2282} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2466} INFO -  at 23.6s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2282} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2466} INFO -  at 23.6s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2282} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2466} INFO -  at 23.8s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:08] {2282} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:09] {2466} INFO -  at 24.2s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:09] {2282} INFO - iteration 129, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:39:09] {2466} INFO -  at 24.4s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:09] {2282} INFO - iteration 130, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:09] {2466} INFO -  at 24.5s,\testimator extra_tree's best error=0.0652,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:09] {2282} INFO - iteration 131, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:10] {2466} INFO -  at 25.1s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:10] {2282} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:10] {2466} INFO -  at 25.8s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:10] {2282} INFO - iteration 133, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:11] {2466} INFO -  at 25.9s,\testimator extra_tree's best error=0.0652,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:11] {2282} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:11] {2466} INFO -  at 26.2s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:11] {2282} INFO - iteration 135, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:39:11] {2466} INFO -  at 26.3s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:11] {2282} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:12] {2466} INFO -  at 27.2s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:12] {2282} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:39:12] {2466} INFO -  at 27.4s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:12] {2282} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl.logger: 10-09 14:39:13] {2466} INFO -  at 28.2s,\testimator xgboost's best error=0.0411,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:13] {2282} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:13] {2466} INFO -  at 28.3s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:13] {2282} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:13] {2466} INFO -  at 28.5s,\testimator extra_tree's best error=0.0652,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:13] {2282} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2466} INFO -  at 28.9s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2282} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2466} INFO -  at 29.1s,\testimator extra_tree's best error=0.0567,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2282} INFO - iteration 143, current learner rf\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2466} INFO -  at 29.1s,\testimator rf's best error=0.0637,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2282} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2466} INFO -  at 29.3s,\testimator xgb_limitdepth's best error=0.0439,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2282} INFO - iteration 145, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2466} INFO -  at 29.4s,\testimator extra_tree's best error=0.0567,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2282} INFO - iteration 146, current learner extra_tree\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2466} INFO -  at 29.5s,\testimator extra_tree's best error=0.0567,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:14] {2282} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 10-09 14:39:15] {2466} INFO -  at 29.9s,\testimator lgbm's best error=0.0397,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:15] {2282} INFO - iteration 148, current learner lrl1\n",
      "[flaml.automl.logger: 10-09 14:39:15] {2466} INFO -  at 30.4s,\testimator lrl1's best error=0.0807,\tbest estimator lgbm's best error=0.0397\n",
      "[flaml.automl.logger: 10-09 14:39:15] {2724} INFO - retrain lgbm for 0.4s\n",
      "[flaml.automl.logger: 10-09 14:39:15] {2727} INFO - retrained model: LGBMClassifier(learning_rate=np.float64(0.485338117349209), max_bin=31,\n",
      "               min_child_samples=4, n_estimators=124, n_jobs=-1, num_leaves=41,\n",
      "               reg_alpha=np.float64(0.003961317913237049),\n",
      "               reg_lambda=np.float64(0.08140919835716444), verbose=-1)\n",
      "[flaml.automl.logger: 10-09 14:39:15] {2009} INFO - fit succeeded\n",
      "[flaml.automl.logger: 10-09 14:39:15] {2010} INFO - Time taken to find the best model: 13.65657663345337\n",
      "FLAML score: 0.9504837791690381\n",
      "FLAML best model: lgbm\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "ml = AutoML()\n",
    "ml.fit(x_train, y_train, task=\"classification\", time_budget=30, metric='accuracy', seed=42)\n",
    "print(\"FLAML score:\", ml.score(x_test, y_test))\n",
    "print(\"FLAML best model:\", ml.best_estimator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60aed0",
   "metadata": {},
   "source": [
    "#### AI DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbec7e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8784 entries, 0 to 8783\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   Date/Time                      8784 non-null   datetime64[ns]\n",
      " 1   Temp_C                         8784 non-null   float64       \n",
      " 2   Dew Point Temp_C               8784 non-null   float64       \n",
      " 3   Rel Hum_%                      8784 non-null   int64         \n",
      " 4   Wind Speed_km/h                8784 non-null   int64         \n",
      " 5   Visibility_km                  8784 non-null   float64       \n",
      " 6   Press_kPa                      8784 non-null   float64       \n",
      " 7   Weather                        8784 non-null   object        \n",
      " 8   Delivery_Risk                  8784 non-null   object        \n",
      " 9   Labelled_Delivery_Risk         8784 non-null   int64         \n",
      " 10  Temp_C_rolling_mean            8784 non-null   float64       \n",
      " 11  Temp_C_rolling_std             8784 non-null   float64       \n",
      " 12  Dew Point Temp_C_rolling_mean  8784 non-null   float64       \n",
      " 13  Dew Point Temp_C_rolling_std   8784 non-null   float64       \n",
      " 14  Rel Hum_%_rolling_mean         8784 non-null   float64       \n",
      " 15  Rel Hum_%_rolling_std          8784 non-null   float64       \n",
      " 16  Wind Speed_km/h_rolling_mean   8784 non-null   float64       \n",
      " 17  Wind Speed_km/h_rolling_std    8784 non-null   float64       \n",
      " 18  Visibility_km_rolling_mean     8784 non-null   float64       \n",
      " 19  Visibility_km_rolling_std      8784 non-null   float64       \n",
      " 20  Press_kPa_rolling_mean         8784 non-null   float64       \n",
      " 21  Press_kPa_rolling_std          8784 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(16), int64(3), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc9c98a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Insights:\n",
      " ## Logistics Delivery Risk Analysis - Actionable Insights\n",
      "\n",
      "Here's an analysis of the provided dataset, focusing on identifying risk factors impacting delivery operations and suggesting actionable steps.\n",
      "\n",
      "**Executive Summary:**\n",
      "\n",
      "The dataset reveals strong correlations between weather conditions (Temperature, Dew Point, Relative Humidity, Visibility) and delivery risk.  Specifically, lower temperatures, high humidity, and reduced visibility are associated with increased risk.  The rolling statistics suggest that sudden changes in these conditions are also significant.  A substantial number of outliers exist in several weather variables, indicating potentially extreme conditions that require specific attention.\n",
      "\n",
      "**1. Key Risk Factors & Correlations:**\n",
      "\n",
      "*   **Temperature & Delivery Risk (Correlation: 0.47):**  A positive correlation indicates that lower temperatures are associated with higher delivery risk. This could be due to ice, snow, or increased driver discomfort impacting efficiency.\n",
      "*   **Dew Point & Delivery Risk (Correlation: 0.35):** Similar to temperature, a positive correlation suggests that higher dew points (indicating more moisture in the air) contribute to increased risk, potentially leading to fog or slippery conditions.\n",
      "*   **Relative Humidity & Delivery Risk (Correlation: -0.38):** A negative correlation suggests that higher relative humidity is associated with increased delivery risk. This could be due to fog, rain, or snow.\n",
      "*   **Visibility & Delivery Risk (Correlation: 0.43):** A positive correlation indicates that lower visibility is strongly linked to higher delivery risk. This is a critical factor as it directly impacts driver safety and delivery times.\n",
      "*   **Rolling Statistics as Leading Indicators:** The rolling mean and standard deviation of weather variables are crucial.  A *sudden increase* in the standard deviation of temperature, humidity, or wind speed suggests rapidly changing conditions that could create unexpected hazards.\n",
      "*   **Pressure & Delivery Risk (Correlation: 0.10):** A slight positive correlation suggests that lower atmospheric pressure may be associated with increased delivery risk. This could be due to storms or adverse weather systems.\n",
      "\n",
      "**2. Anomaly Detection & Outlier Analysis:**\n",
      "\n",
      "*   **Significant Outliers:** The dataset contains a substantial number of outliers in `Temp_C`, `Dew Point Temp_C`, `Rel Hum_%`, `Wind Speed_km/h`, `Visibility_km`, and `Press_kPa`. These represent extreme weather events.\n",
      "*   **Visibility Outliers:** The high number of outliers in `Visibility_km` (378) is particularly concerning. These events likely represent periods of dense fog, heavy rain, or snowstorms.\n",
      "*   **Rolling Standard Deviation Outliers:** High numbers of outliers in rolling standard deviation columns indicate periods of rapid weather changes.\n",
      "\n",
      "**3. Actionable Insights & Recommendations:**\n",
      "\n",
      "Here's a breakdown of recommendations, categorized by impact and action:\n",
      "\n",
      "*   **Impact: Reduced Delivery Success Rate & Increased Accidents**\n",
      "    *   **Recommendation: Dynamic Route Optimization based on Real-Time Weather:** Implement a system that dynamically adjusts delivery routes based on real-time weather data (temperature, humidity, visibility, wind speed). Prioritize deliveries in areas with favorable conditions. *Impact: 10-15% improvement in on-time delivery during adverse weather.*\n",
      "    *   **Recommendation: Visibility Thresholds & Delivery Holds:** Establish a minimum visibility threshold (e.g., 5km).  Automatically pause deliveries in areas where visibility falls below this threshold. *Impact: Significant reduction in accident rates during low-visibility events.*\n",
      "\n",
      "*   **Impact: Increased Delivery Costs (Fuel, Driver Time)**\n",
      "    *   **Recommendation: Predictive Maintenance Scheduling:** Use temperature data to predict potential vehicle maintenance needs (e.g., battery performance in cold weather, tire pressure adjustments). *Impact: 5-10% reduction in vehicle maintenance costs.*\n",
      "    *   **Recommendation: Driver Training on Adverse Weather Conditions:** Provide specialized training to drivers on safe driving practices in low-visibility, icy, or windy conditions. *Impact: Improved driver safety and reduced delivery delays.*\n",
      "\n",
      "*   **Impact: Improved Resource Allocation & Proactive Planning**\n",
      "    *   **Recommendation: Weather-Based Staffing Adjustments:**  Increase staffing levels in areas expecting severe weather.  Pre-position vehicles and resources in strategic locations. *Impact: Enhanced responsiveness to weather-related disruptions.*\n",
      "    *   **Recommendation: Utilize Rolling Statistics for Early Warning:** Monitor the rolling standard deviation of weather variables.  A significant increase should trigger alerts and proactive planning. *Impact:  Improved preparedness for rapidly changing conditions.*\n",
      "    *   **Recommendation: Integrate Weather Forecasts:** Incorporate short-term and long-term weather forecasts into delivery planning. *Impact: Proactive adjustments to delivery schedules and resource allocation.*\n",
      "\n",
      "*   **Impact: Enhanced Customer Communication & Satisfaction**\n",
      "    *   **Recommendation: Proactive Delivery Notifications:**  Inform customers of potential delays due to adverse weather conditions. Provide estimated delivery windows. *Impact: Increased customer satisfaction and reduced support inquiries.*\n",
      "\n",
      "**4. Further Analysis:**\n",
      "\n",
      "*   **Temporal Patterns:** Analyze weather patterns and delivery risk over time (daily, weekly, seasonal). This can help identify recurring risks and optimize resource allocation.\n",
      "*   **Geographic Analysis:** Map delivery risk levels across different geographic regions. This can reveal areas that are consistently more vulnerable to weather-related disruptions.\n",
      "*   **Correlation with Delivery Time:** Investigate the correlation between weather variables and actual delivery times. This can help quantify the impact of weather on delivery efficiency.\n",
      "*   **Machine Learning Model:** Develop a machine learning model to predict delivery risk based on weather data and other relevant features. This can enable proactive risk mitigation.\n",
      "\n",
      "\n",
      "\n",
      "**Data Considerations:**\n",
      "\n",
      "*   **Data Granularity:** The current dataset appears to be at a relatively high granularity.  Consider incorporating more granular data (e.g., hourly weather updates) for improved accuracy.\n",
      "*   **External Data Sources:** Integrate external data sources, such as road conditions and traffic data, to enhance the risk assessment.\n",
      "\n",
      "\n",
      "\n",
      "By implementing these recommendations, logistics operations can significantly mitigate the impact of weather-related disruptions, improve delivery efficiency, enhance driver safety, and increase customer satisfaction.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df_numeric = df[numeric_cols]\n",
    "\n",
    "missing_values = df.isna().sum()\n",
    "correlations = df_numeric.corr()\n",
    "outliers = ((df_numeric < df_numeric.quantile(0.05)) | (df_numeric > df_numeric.quantile(0.95))).sum()\n",
    "summary_stats = df_numeric.describe().T\n",
    "\n",
    "# Summarize data (so the model doesn't get overloaded with raw rows)\n",
    "summary = f\"\"\"\n",
    "Dataset Summary:\n",
    "    - Rows: {df.shape[0]}\n",
    "    - Columns: {df.shape[1]}\n",
    "    - Missing Values: {missing_values.to_dict()}\n",
    "    - Numeric Summary: {summary_stats.head(5).to_dict()}\n",
    "    - Feature Correlations: {correlations.to_dict()}\n",
    "    - Potential Outliers (count per column): {outliers.to_dict()}\n",
    "\n",
    "    Target: {df[\"Labelled_Delivery_Risk\"]}\n",
    "    Task: \"classification\"\n",
    "\"\"\"\n",
    "\n",
    "# Query OpenRequests API (gemma-3-27b)\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "HF_TOKEN = os.getenv(\"Auto_DA\")\n",
    "HEADERS = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}  # Make sure HF_TOKEN is set in environment\n",
    "payload = {\n",
    "    \"model\": \"google/gemma-3-27b-it:free\",\n",
    "    \"messages\" : [{\n",
    "        \"role\":\"user\",\n",
    "        \"content\" : f\"\"\"You are a senior Data Analyst in logistics. Analyze the dataset {summary} and provide actionable insights that could impact delivery operations. \n",
    "        - Highlight risk factors from weather and other features.\n",
    "        - Suggest preventive or operational actions.\n",
    "        - Focus on correlations, anomalies, and patterns over time.\n",
    "        - Provide bullet points with impact and recommendation.\n",
    "        - Make sure these insights are industry-relevant and practical and are related to dataset but not general information.\n",
    "        \"\"\"}]\n",
    "        }\n",
    "\n",
    "response = requests.post(url, headers= HEADERS,json=payload, stream=True)\n",
    "\n",
    "# Error detection\n",
    "if response.status_code != 200:\n",
    "    print(f\"HF API error: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "# Extract AI reply\n",
    "data = response.json()\n",
    "try:\n",
    "    reply = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    with open(\"AI_Report.txt\", \"w\") as f:\n",
    "        f.write(reply)\n",
    "    print(\"\\nAI Insights:\\n\", reply)\n",
    "except (KeyError, IndexError):\n",
    "    print(str(data))\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
